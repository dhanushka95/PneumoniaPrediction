{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deepkeras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deepkeras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deepkeras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deepkeras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deepkeras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deepkeras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deepkeras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deepkeras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deepkeras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deepkeras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deepkeras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\deepkeras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\deepkeras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\deepkeras\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,MaxPooling2D,Convolution2D,Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Initialising the CNN\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(32,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(16,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(8,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "#Compiling the CNN\n",
    "model.compile(optimizer = 'rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale=1./255,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5215 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "'Preprocess/train',\n",
    "target_size=(64, 64),\n",
    "batch_size=32,\n",
    "class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "'PreProcess/test',\n",
    "target_size=(64,64),\n",
    "batch_size=32,\n",
    "class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "163/163 [==============================] - 642s 4s/step - loss: 0.5625 - accuracy: 0.7452 - val_loss: 0.4962 - val_accuracy: 0.7869\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 541s 3s/step - loss: 0.4184 - accuracy: 0.8115 - val_loss: 0.4732 - val_accuracy: 0.8013\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 561s 3s/step - loss: 0.3176 - accuracy: 0.8604 - val_loss: 0.2530 - val_accuracy: 0.8574\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 528s 3s/step - loss: 0.2824 - accuracy: 0.8830 - val_loss: 0.1933 - val_accuracy: 0.8606\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 561s 3s/step - loss: 0.2548 - accuracy: 0.8963 - val_loss: 0.2298 - val_accuracy: 0.8446\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 549s 3s/step - loss: 0.2289 - accuracy: 0.9105 - val_loss: 0.3720 - val_accuracy: 0.8990\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 486s 3s/step - loss: 0.2052 - accuracy: 0.9197 - val_loss: 0.4277 - val_accuracy: 0.9022\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 477s 3s/step - loss: 0.1968 - accuracy: 0.9244 - val_loss: 0.4503 - val_accuracy: 0.9071\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 482s 3s/step - loss: 0.1868 - accuracy: 0.9254 - val_loss: 0.5741 - val_accuracy: 0.8958\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 572s 4s/step - loss: 0.1886 - accuracy: 0.9252 - val_loss: 0.1987 - val_accuracy: 0.9087\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 429s 3s/step - loss: 0.1825 - accuracy: 0.9310 - val_loss: 0.3774 - val_accuracy: 0.9054\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 447s 3s/step - loss: 0.1745 - accuracy: 0.9306 - val_loss: 0.7210 - val_accuracy: 0.8958\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 426s 3s/step - loss: 0.1808 - accuracy: 0.9377 - val_loss: 0.1713 - val_accuracy: 0.9087\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 522s 3s/step - loss: 0.1638 - accuracy: 0.9363 - val_loss: 0.0560 - val_accuracy: 0.8894\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 457s 3s/step - loss: 0.1579 - accuracy: 0.9392 - val_loss: 0.1053 - val_accuracy: 0.8990\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 486s 3s/step - loss: 0.1664 - accuracy: 0.9406 - val_loss: 0.4598 - val_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 429s 3s/step - loss: 0.1581 - accuracy: 0.9444 - val_loss: 0.3880 - val_accuracy: 0.9231\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 436s 3s/step - loss: 0.1574 - accuracy: 0.9425 - val_loss: 0.2274 - val_accuracy: 0.9054\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 438s 3s/step - loss: 0.1510 - accuracy: 0.9463 - val_loss: 0.3351 - val_accuracy: 0.8942\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 450s 3s/step - loss: 0.1573 - accuracy: 0.9386 - val_loss: 0.4304 - val_accuracy: 0.8830\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 472s 3s/step - loss: 0.1471 - accuracy: 0.9461 - val_loss: 0.3516 - val_accuracy: 0.9151\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 432s 3s/step - loss: 0.1481 - accuracy: 0.9442 - val_loss: 0.3582 - val_accuracy: 0.9038\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 449s 3s/step - loss: 0.1454 - accuracy: 0.9521 - val_loss: 0.2367 - val_accuracy: 0.8590\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 484s 3s/step - loss: 0.1394 - accuracy: 0.9517 - val_loss: 0.3630 - val_accuracy: 0.9071\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 427s 3s/step - loss: 0.1414 - accuracy: 0.9478 - val_loss: 0.2431 - val_accuracy: 0.8830\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 434s 3s/step - loss: 0.1448 - accuracy: 0.9507 - val_loss: 0.0552 - val_accuracy: 0.9071\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 429s 3s/step - loss: 0.1334 - accuracy: 0.9536 - val_loss: 0.3171 - val_accuracy: 0.8686\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 430s 3s/step - loss: 0.1315 - accuracy: 0.9507 - val_loss: 0.1826 - val_accuracy: 0.9199\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 530s 3s/step - loss: 0.1309 - accuracy: 0.9549 - val_loss: 0.3550 - val_accuracy: 0.9087\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 542s 3s/step - loss: 0.1399 - accuracy: 0.9509 - val_loss: 0.3039 - val_accuracy: 0.8878\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 487s 3s/step - loss: 0.1396 - accuracy: 0.9517 - val_loss: 0.3273 - val_accuracy: 0.9119\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 444s 3s/step - loss: 0.1350 - accuracy: 0.9532 - val_loss: 0.5581 - val_accuracy: 0.9151\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 434s 3s/step - loss: 0.1272 - accuracy: 0.9561 - val_loss: 0.2662 - val_accuracy: 0.8862\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 495s 3s/step - loss: 0.1292 - accuracy: 0.9519 - val_loss: 0.2039 - val_accuracy: 0.9167\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 447s 3s/step - loss: 0.1168 - accuracy: 0.9569 - val_loss: 0.4471 - val_accuracy: 0.9151\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 449s 3s/step - loss: 0.1297 - accuracy: 0.9519 - val_loss: 0.4642 - val_accuracy: 0.8830\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 450s 3s/step - loss: 0.1295 - accuracy: 0.9523 - val_loss: 0.2408 - val_accuracy: 0.9071\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 449s 3s/step - loss: 0.1261 - accuracy: 0.9530 - val_loss: 0.4340 - val_accuracy: 0.9119\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 494s 3s/step - loss: 0.1306 - accuracy: 0.9517 - val_loss: 0.0589 - val_accuracy: 0.9279\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 458s 3s/step - loss: 0.1212 - accuracy: 0.9546 - val_loss: 0.3285 - val_accuracy: 0.8910\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 448s 3s/step - loss: 0.1245 - accuracy: 0.9530 - val_loss: 0.0457 - val_accuracy: 0.9263\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 458s 3s/step - loss: 0.1247 - accuracy: 0.9540 - val_loss: 0.4055 - val_accuracy: 0.9135\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 459s 3s/step - loss: 0.1192 - accuracy: 0.9588 - val_loss: 0.2635 - val_accuracy: 0.9279\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 438s 3s/step - loss: 0.1227 - accuracy: 0.9553 - val_loss: 0.6583 - val_accuracy: 0.8798\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 430s 3s/step - loss: 0.1213 - accuracy: 0.9555 - val_loss: 0.0886 - val_accuracy: 0.9103\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 456s 3s/step - loss: 0.1247 - accuracy: 0.9584 - val_loss: 0.1882 - val_accuracy: 0.8894\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 528s 3s/step - loss: 0.1152 - accuracy: 0.9582 - val_loss: 0.0390 - val_accuracy: 0.9231\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 431s 3s/step - loss: 0.1111 - accuracy: 0.9620 - val_loss: 0.4508 - val_accuracy: 0.9151\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 745s 5s/step - loss: 0.1185 - accuracy: 0.9584 - val_loss: 0.2785 - val_accuracy: 0.9054\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 487s 3s/step - loss: 0.1225 - accuracy: 0.9580 - val_loss: 0.1795 - val_accuracy: 0.9038\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 508s 3s/step - loss: 0.1192 - accuracy: 0.9613 - val_loss: 0.1635 - val_accuracy: 0.9119\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 597s 4s/step - loss: 0.1155 - accuracy: 0.9590 - val_loss: 0.2166 - val_accuracy: 0.9151\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 518s 3s/step - loss: 0.1139 - accuracy: 0.9588 - val_loss: 0.0959 - val_accuracy: 0.9135\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 532s 3s/step - loss: 0.1294 - accuracy: 0.9567 - val_loss: 0.5399 - val_accuracy: 0.9006\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 479s 3s/step - loss: 0.1146 - accuracy: 0.9595 - val_loss: 0.2963 - val_accuracy: 0.8926\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 449s 3s/step - loss: 0.1209 - accuracy: 0.9586 - val_loss: 0.2539 - val_accuracy: 0.8926\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 437s 3s/step - loss: 0.1147 - accuracy: 0.9567 - val_loss: 0.5464 - val_accuracy: 0.8974\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 465s 3s/step - loss: 0.1168 - accuracy: 0.9569 - val_loss: 0.3592 - val_accuracy: 0.9231\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 470s 3s/step - loss: 0.1346 - accuracy: 0.9524 - val_loss: 0.0461 - val_accuracy: 0.9087\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 450s 3s/step - loss: 0.1256 - accuracy: 0.9555 - val_loss: 0.6156 - val_accuracy: 0.9087\n",
      "Epoch 61/100\n",
      "163/163 [==============================] - 627s 4s/step - loss: 0.1118 - accuracy: 0.9597 - val_loss: 0.1183 - val_accuracy: 0.8734\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 551s 3s/step - loss: 0.1135 - accuracy: 0.9588 - val_loss: 0.5168 - val_accuracy: 0.8109\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 477s 3s/step - loss: 0.1097 - accuracy: 0.9611 - val_loss: 0.4134 - val_accuracy: 0.9135\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 454s 3s/step - loss: 0.1179 - accuracy: 0.9578 - val_loss: 0.0064 - val_accuracy: 0.9183\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 430s 3s/step - loss: 0.1195 - accuracy: 0.9584 - val_loss: 0.0413 - val_accuracy: 0.9022\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 497s 3s/step - loss: 0.1097 - accuracy: 0.9599 - val_loss: 0.1782 - val_accuracy: 0.8846\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 439s 3s/step - loss: 0.1312 - accuracy: 0.9582 - val_loss: 0.3494 - val_accuracy: 0.8926\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 519s 3s/step - loss: 0.1181 - accuracy: 0.9567 - val_loss: 0.0503 - val_accuracy: 0.9247\n",
      "Epoch 69/100\n",
      "163/163 [==============================] - 517s 3s/step - loss: 0.1104 - accuracy: 0.9592 - val_loss: 0.0453 - val_accuracy: 0.8958\n",
      "Epoch 70/100\n",
      "163/163 [==============================] - 493s 3s/step - loss: 0.1214 - accuracy: 0.9601 - val_loss: 0.6225 - val_accuracy: 0.9119\n",
      "Epoch 71/100\n",
      "163/163 [==============================] - 448s 3s/step - loss: 0.1182 - accuracy: 0.9615 - val_loss: 0.1430 - val_accuracy: 0.9151\n",
      "Epoch 72/100\n",
      "163/163 [==============================] - 469s 3s/step - loss: 0.1224 - accuracy: 0.9561 - val_loss: 0.3916 - val_accuracy: 0.9215\n",
      "Epoch 73/100\n",
      "163/163 [==============================] - 459s 3s/step - loss: 0.1224 - accuracy: 0.9595 - val_loss: 1.0857 - val_accuracy: 0.8926\n",
      "Epoch 74/100\n",
      "163/163 [==============================] - 436s 3s/step - loss: 0.1196 - accuracy: 0.9605 - val_loss: 0.1553 - val_accuracy: 0.9215\n",
      "Epoch 75/100\n",
      "163/163 [==============================] - 514s 3s/step - loss: 0.1452 - accuracy: 0.9588 - val_loss: 0.1294 - val_accuracy: 0.8878\n",
      "Epoch 76/100\n",
      "163/163 [==============================] - 505s 3s/step - loss: 0.1215 - accuracy: 0.9584 - val_loss: 0.0196 - val_accuracy: 0.9071\n",
      "Epoch 77/100\n",
      "163/163 [==============================] - 451s 3s/step - loss: 0.1268 - accuracy: 0.9565 - val_loss: 0.1461 - val_accuracy: 0.9103\n",
      "Epoch 78/100\n",
      "163/163 [==============================] - 426s 3s/step - loss: 0.1341 - accuracy: 0.9584 - val_loss: 0.0594 - val_accuracy: 0.9038\n",
      "Epoch 79/100\n",
      "163/163 [==============================] - 436s 3s/step - loss: 0.1400 - accuracy: 0.9559 - val_loss: 0.6292 - val_accuracy: 0.9022\n",
      "Epoch 80/100\n",
      "163/163 [==============================] - 459s 3s/step - loss: 0.1155 - accuracy: 0.9615 - val_loss: 0.6454 - val_accuracy: 0.8558\n",
      "Epoch 81/100\n",
      "163/163 [==============================] - 440s 3s/step - loss: 0.1230 - accuracy: 0.9557 - val_loss: 0.0911 - val_accuracy: 0.8958\n",
      "Epoch 82/100\n",
      "163/163 [==============================] - 469s 3s/step - loss: 0.1418 - accuracy: 0.9553 - val_loss: 0.2492 - val_accuracy: 0.9151\n",
      "Epoch 83/100\n",
      "163/163 [==============================] - 478s 3s/step - loss: 0.1369 - accuracy: 0.9616 - val_loss: 0.0533 - val_accuracy: 0.9022\n",
      "Epoch 84/100\n",
      "163/163 [==============================] - 495s 3s/step - loss: 0.1165 - accuracy: 0.9592 - val_loss: 0.1296 - val_accuracy: 0.9247\n",
      "Epoch 85/100\n",
      "163/163 [==============================] - 486s 3s/step - loss: 0.1236 - accuracy: 0.9542 - val_loss: 0.1849 - val_accuracy: 0.9103\n",
      "Epoch 86/100\n",
      "163/163 [==============================] - 434s 3s/step - loss: 0.1158 - accuracy: 0.9611 - val_loss: 0.2265 - val_accuracy: 0.9231\n",
      "Epoch 87/100\n",
      "163/163 [==============================] - 459s 3s/step - loss: 0.1244 - accuracy: 0.9595 - val_loss: 0.2838 - val_accuracy: 0.9103\n",
      "Epoch 88/100\n",
      "163/163 [==============================] - 435s 3s/step - loss: 0.1254 - accuracy: 0.9572 - val_loss: 0.3482 - val_accuracy: 0.9071\n",
      "Epoch 89/100\n",
      "163/163 [==============================] - 511s 3s/step - loss: 0.1248 - accuracy: 0.9586 - val_loss: 0.1434 - val_accuracy: 0.8750\n",
      "Epoch 90/100\n",
      "163/163 [==============================] - 491s 3s/step - loss: 0.1203 - accuracy: 0.9592 - val_loss: 0.7302 - val_accuracy: 0.8990\n",
      "Epoch 91/100\n",
      "163/163 [==============================] - 464s 3s/step - loss: 0.1347 - accuracy: 0.9622 - val_loss: 0.1341 - val_accuracy: 0.9071\n",
      "Epoch 92/100\n",
      "163/163 [==============================] - 502s 3s/step - loss: 0.1166 - accuracy: 0.9592 - val_loss: 1.2503 - val_accuracy: 0.7756\n",
      "Epoch 93/100\n",
      "163/163 [==============================] - 439s 3s/step - loss: 0.1241 - accuracy: 0.9613 - val_loss: 0.2078 - val_accuracy: 0.8926\n",
      "Epoch 94/100\n",
      "163/163 [==============================] - 448s 3s/step - loss: 0.1451 - accuracy: 0.9603 - val_loss: 0.2250 - val_accuracy: 0.9022\n",
      "Epoch 95/100\n",
      "163/163 [==============================] - 441s 3s/step - loss: 0.1212 - accuracy: 0.9611 - val_loss: 0.3965 - val_accuracy: 0.8846\n",
      "Epoch 96/100\n",
      "163/163 [==============================] - 461s 3s/step - loss: 0.1229 - accuracy: 0.9580 - val_loss: 0.3654 - val_accuracy: 0.8958\n",
      "Epoch 97/100\n",
      "163/163 [==============================] - 444s 3s/step - loss: 0.1193 - accuracy: 0.9628 - val_loss: 0.3074 - val_accuracy: 0.9006\n",
      "Epoch 98/100\n",
      "163/163 [==============================] - 437s 3s/step - loss: 0.1262 - accuracy: 0.9599 - val_loss: 0.7866 - val_accuracy: 0.8718\n",
      "Epoch 99/100\n",
      "163/163 [==============================] - 524s 3s/step - loss: 0.1281 - accuracy: 0.9638 - val_loss: 0.0563 - val_accuracy: 0.8958\n",
      "Epoch 100/100\n",
      "163/163 [==============================] - 470s 3s/step - loss: 0.1254 - accuracy: 0.9561 - val_loss: 0.1743 - val_accuracy: 0.9038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x197bc330b38>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(MyThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        val_acc = logs[\"val_accuracy\"]\n",
    "        if val_acc >= self.threshold:\n",
    "            self.model.save(str(val_acc)+'_model.h5')\n",
    "\n",
    "            \n",
    "my_callback = MyThresholdCallback(threshold=0.9) \n",
    "model.fit_generator(\n",
    "training_set,\n",
    "epochs=100,\n",
    "validation_data=test_set,callbacks=[my_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
